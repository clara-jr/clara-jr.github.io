---
layout: ../../layouts/PostLayout.astro
title: 'Aprendizaje Adaptativo con Python üë©üèª‚Äçüíª'
pubDate: 2023/12/01
description: 'Podemos personalizar la experiencia de aprendizaje de cada estudiante en funci√≥n de sus habilidades y necesidades gracias al aprendizaje autom√°tico'
author: 'Clara Jim√©nez'
image:
    url: '/images/posts/adaptative-learning.jpg' 
    alt: 'Aprendizaje Adaptativo con Python'
tags: ["machine learning", "python"]
draft: true
---
Si estamos intentando ofrecer contenido educativo a un grupo de estudiantes para que mejoren sus conocimientos sobre alg√∫n tema en particular, y queremos cerciorarnos de que todos consiguen adquirir dichos conocimientos exitosamente, debemos ser conscientes de que cada cual tendr√° unas habilidades y necesidades distintas. Visto esto, resulta evidente pensar que una misma estrategia educativa no desencadenar√° los mismos resultados en todos los estudiantes. Es aqu√≠ donde aparece la necesidad de ofrecer una experiencia de aprendizaje adaptada a las necesidades de cada estudiante. Y cuando esta experiencia va a ofrecerse a trav√©s de la tecnolog√≠a (p.ej. un curso online), podremos ayudarnos de la misma para favorecer esta adaptaci√≥n del contenido. La idea es conseguir guiar a cada estudiante de manera distinta a lo largo del curso seg√∫n sus habilidades. De esta manera, todos conseguir√°n aprender lo mismo aunque de forma diferente, adaptada a sus necesidades. Haciendo uso del an√°lisis de datos y aprendizaje autom√°tico, podremos adaptar el proceso de aprendizaje en tiempo real. Mediante un an√°lisis de los aciertos y errores de cada estudiante, podremos conocer el estado del conocimiento adquirido hasta un momento espec√≠fico y podremos decidir as√≠ si ofrecemos o no un apoyo educativo adicional con intenci√≥n de afianzar conceptos.

![Aprendizaje Adaptativo](/images/posts/adaptative-learning.jpg)

El escenario m√°s simplificado en el que podemos aplicar aprendizaje adaptativo podr√≠a ser un curso en el que tuvi√©ramos una bifurcaci√≥n entre 2 caminos en un momento dado. Por ejemplo, si a mitad del curso se detecta que un estudiante no est√° adquiriendo los conocimientos suficientes con soltura, se le desviar√° a un camino con un mayor refuerzo de dichos conocimientos antes de terminar el proceso de aprendizaje. Sin embargo, aquel estudiante que demuestre haber interiorizado adecuadamente las competencias oportunas, ser√° desviado hacia el camino m√°s √°gil para poder terminar con su experiencia de aprendizaje. Yendo un poco m√°s all√°, en lugar de tener 2 caminos en un punto determinado del curso, podemos tener este tipo de contenido adaptativo a lo largo de todo el curso, pudiendo decidir en tiempo real si se ofrece contenido de refuerzo al estudiante en un determinado punto o no.

## Selecci√≥n de atributos

Para poder implementar un sistema de aprendizaje adaptativo, lo primero que necesitaremos ser√° **disponer de datos** sobre los estudiantes que previamente hayan ido pasando por nuestros cursos. Tendremos que analizar qu√© informaci√≥n puede ser relevante para el objetivo que nos planteamos, por ejemplo: aciertos y fallos en cuestionarios, tiempo de lectura de documentaci√≥n o de resoluci√≥n de preguntas, ayuda o pistas solicitadas a lo largo del curso, etc.

A su vez, es importante no utilizar valores absolutos de los atributos (tiempos/fallos/pistas/etc.) que decidamos integrar en nuestros datos, ya que esto no nos servir√≠a si debemos desviar a un estudiante entre 2 caminos en un punto intermedio de un curso, porque el algoritmo habr√≠a sido entrenado con datos de un orden bastante mayor y no comparable con los datos de entrada del nuevo estudiante. Para que las √≥rdenes de magnitud sean comparables, deber√≠amos trabajar con **datos relativos** en lugar de absolutos o acumulativos. En lugar de utilizar, por ejemplo, el n√∫mero de cuestionarios fallados, deberemos trabajar con el porcentaje de cuestionarios fallados, teniendo en cuenta por tanto cu√°ntos cuestionarios tiene el curso en cuesti√≥n.

Adem√°s, dado que cada curso puede ser *de su padre y de su madre* (la cantidad de cuestionarios y su dificultad, la densidad de la documentaci√≥n a leer, etc.) puede ser de utilidad para el modelo **tener informaci√≥n sobre a qu√© curso pertenece cada entrada de datos**. Adem√°s, para tratar de predecir informaci√≥n sobre si ofrecer refuerzo o no a un estudiante que est√© cursando un curso con el que no hayamos entrenado nuestro modelo todav√≠a, conviene haber entrenado nuestro modelo con datos de diversos cursos y no solo de uno, para que tenga un conocimiento m√°s generalizado del problema. Por estos motivos, es recomendable utilizar datos de entrenamiento (y test) de distintos cursos y a√±adir un atributo identificativo del curso a esos datos. Dado que **los algoritmos de aprendizaje autom√°tico supervisado no admiten strings**, ese identificador del curso deber√° tener un valor num√©rico. Para esto, asumiendo que generalmente trabajamos con idetificadores en formato string hexadecimal, podemos utilizar un conversor de hexadecimal a entero en base 10: `dataframe = pd.read_csv("data.csv", converters={"courseId": lambda x: int(x, 16)})`. Esta conversi√≥n es adecuada ya que es **determinista**, de forma que cuando tengamos que hacer una predicci√≥n con un nuevo dato, asignaremos el mismo valor entero a este identificador que en el resto de datos de entrenamiento utilizados relativos al mismo curso.

Otro atributo importante que podemos tener en cuenta es un identificador del usuario que est√° realizando el curso. De esta manera, podr√° resultar relevante lo que un estudiante haga en cursos anteriores a la hora de decidir por qu√© camino dirigirle en un nuevo curso. Entendemos que es informaci√≥n relevante si un estudiante tiende generalmente a ser √°gil o, por el contrario, suele necesitar refuerzo, y para eso necesitamos identificar a qu√© usuario pertenece cada entrada de datos. A este identificador habr√° que aplicarle la misma transformaci√≥n a n√∫mero entero que se le aplique al identificador de curso.

## Etiquetado de datos

Una vez hecho un an√°lisis previo sobre qu√© informaci√≥n podemos considerar relevante a priori para nuestro modelo de aprendizaje autom√°tico, es hora de realizar un segundo an√°lisis m√°s exhaustivo y apoyado por gr√°ficas. As√≠, para hacer esta valoraci√≥n y selecci√≥n de atributos, podremos tratar de interpretar gr√°ficas utilizando `pandas` para recuperar los datos de los que disponemos en un CSV y `matplotlib.pyplot` para *graficarlos*. Una vez escogidos los atributos, desechamos el resto de columnas y transformamos nuestros datos haciendo uso del `StandardScaler` de `sklearn.preprocessing`.

Una vez tengamos un conjunto de datos con informaci√≥n relevante sobre una amplia cantidad de estudiantes, ser√° momento de **etiquetar nuestros datos**, asignando as√≠ un valor a cada experiencia de aprendizaje sobre si ha sido √°gil o habr√≠a necesitado refuerzo. Dado que dispondremos de una gran cantidad de datos que tendremos que etiquetar, lo mejor ser√° automatizar de alguna manera este etiquetado. Esto lo haremos utilizando **algoritmos de *clustering*** para conseguir agrupar nuestros datos seg√∫n similitudes encontradas en los valores de sus atributos. Esta t√©cnica de aprendizaje autom√°tico se trata de un **aprendizaje no supervisado** dado que no se trabaja con el conocimiento de cu√°l ha de ser el resultado o la salida esperada. El algoritmo de *clustering* dividir√° nuestro conjunto de datos en K grupos (siendo K el valor √≥ptimo marcado por el algoritmo). Ojearemos las caracter√≠sticas de cada grupo y trataremos de identificar si se trata de un grupo √°gil o si, por el contrario, necesitar√≠a refuerzo.

As√≠ pues, concretamente haremos uso del algoritmo de *clustering* **KMeans**[[1]](https://towardsdatascience.com/how-to-perform-kmeans-clustering-using-python-7cc296cec092) de `sklearn.cluster` y trataremos de encontrar el valor √≥ptimo de K (n¬∫ de agrupaciones). Este algoritmo se basa en establecer K centroides aleatorios de entre nuestras entradas de datos y asignar a cada entrada un grupo seg√∫n el centroide que tenga m√°s pr√≥ximo (haciendo uso del c√°lculo de distancias eucl√≠deas entre las entradas de datos y los centroides designados). Una vez agrupados todos los datos, se reasignan los centroides seg√∫n el punto medio de cada uno de los clusters. Con los nuevos centroides, se repite el proceso hasta que la reasignaci√≥n de centroides deje de tener sentido porque ya no se produzcan grandes cambios en la divisi√≥n de clusters. Este proceso debemos repetirlo para varios valores de K y, siguiendo el _m√©todo del codo_ o _elbow method_, encontraremos el valor √≥ptimo de K. Este m√©todo consiste en plasmar en una gr√°fica, para cada valor de K, cu√°l ha sido el resultado de la distancia media de los centroides a los elementos pertenecientes a sus clusters (WCSS). Esta gr√°fica resultar√° tener forma de codo, de ah√≠ el nombre del m√©todo, de forma que para `K=1` tendremos el valor mayor de WCSS y este ir√° disminuyendo r√°pidamente hasta pasar a hacerlo m√°s lentamente o incluso a contemplar ligeras subidas adem√°s de bajadas. El valor K para el que la gr√°fica deja de tener una r√°pida bajada ser√° el √≥ptimo.

Una vez tenemos el valor de K con el que dividir nuestros datos, podemos representar gr√°ficamente y mediante colores los distintos clusters que se han generado. Podemos representar distintas gr√°ficas en funci√≥n de los distintos atributos de los que se componen nuestros datos para tratar de analizar los mismos y determinar qu√© etiqueta llevar√° cada cluster, en funci√≥n de si percibimos que ese cluster necesitar√≠a refuerzo o no.

<script src="https://gist.github.com/clara-jr/253d384afec928d2610f4ee563a2f024.js"></script>

Seg√∫n los resultados del experimento realizado en este *notebook*, por ejemplo, tenemos los siguientes clusters y etiquetas:

- üî¥¬†Rojos, üü¢¬†verdes y üîµ¬†azules: tardan poco en resolver tanto los *quizes* como los *puzzles*, no fallan mucho y no compran soluciones ni piden pistas¬†&rarr;¬†**√Ågil**

- üü£¬†Morados: igual que los anteriores pero fallando m√°s *puzzles*/*quizes* &rarr;¬†a√∫n as√≠ **√Ågil**

- üíì¬†Rosas: fallan bastantes *puzzles* y piden muchas pistas¬†&rarr;¬†**Necesita refuerzo**

- üü°¬†Amarillos: tardan mucho en resolver los *puzzles*/*quizzes* y compran muchas soluciones de *puzzles* &rarr;¬†**Necesita refuerzo**

- üü†¬†Naranjas: tardan poco en resolver los *puzzles*/*quizes* pero fallan muchos *puzzles* y *quizes*¬†&rarr;¬†**Necesita refuerzo**

Una vez etiquetados nuestros datos, generamos un archivo CSV en el que insertamos la columna adicional que representa el resultado de este etiquetado. Estos datos ser√°n los que utilizaremos en la siguiente fase de implementaci√≥n de un sistema de aprendizaje adaptativo.

## Entrenamiento del modelo

Teniendo un conjunto de datos etiquetado, y sabiendo por tanto para cada proceso de aprendizaje analizado si se trata de un proceso √°gil o no, podremos entrenar un modelo con **aprendizaje autom√°tico supervisado** para que aprenda a clasificar futuros estudiantes y a asignar as√≠ caminos educativos con o sin necesidad de refuerzo.

Para hacer este entrenamiento y evaluaci√≥n del modelo, debemos separar los valores de entrada de los valores de salida de nuestros datos, es decir, los atributos que definen cada una de las entradas de datos y la salida que esperamos ser capaces de predecir con nuestro algoritmo de clasificaci√≥n. Seguidamente, haciendo uso de `train_test_split` de `sklearn.model_selection` podemos hacer una separaci√≥n de nuestros datos en **un conjunto de entrenamiento y otro de test**.

Podemos representar gr√°ficas de nuestro conjunto de test para, tras entrenar y evaluar modelos de aprendizaje autom√°tico, poder comparar lo predicho con la realidad y ser capaces de tener una representaci√≥n visual de la calidad de lo predicho. Los puntos rojos üî¥ representar√≠an los estudiantes con necesidad de refuerzo en un curso determinado y en verde üü¢ estar√°n aquellos datos que representen procesos de aprendizaje √°giles.

As√≠, utilizando nuestro conjunto de entrenamiento y continuando con el uso de `sklearn`, podemos entrenar distintos modelos de aprendizaje autom√°tico supervisado[[2]](https://medium.com/thrive-in-ai/classification-algorithms-in-python-5f58a7a27b88) (Logistic Regression, Random Forest, Naive Bayes, KNN, Gradient Boosting, SVM, etc.) para clasificar nuevos datos de entrada, y podemos evaluar los resultados de cada modelo con nuestro conjunto de test. En el experimento realizado en el siguiente *notebook*, vemos c√≥mo se encuentran los mejores resultados con el algoritmo Random Forest.

<script src="https://gist.github.com/clara-jr/4c09c247591a0dc3c2597d047829cfa9.js"></script>

Tras la toma de una decisi√≥n sobre a qu√© camino enviar a un estudiante, es decir, si este requiere cierto refuerzo para interiorizar los conocimientos o no, podr√≠amos optar por reentrenar el modelo con este nuevo dato. Dado que trabajamos con atributos cuyos valores representan informaci√≥n relativa y no cuantitativa, esta realimentaci√≥n podr√≠a realizarse igualmente tras completar el curso o en el instante en el que realizamos la predicci√≥n y la bifurcaci√≥n del proceso de aprendizaje del estudiante.

> ‚ÄúThough the use of artificial intelligence in education is far from a new phenomenon, the technology is poised to radically change the way teachers teach and students learn‚Äù
>
> ###### Dan Ayoub, General Manager of Education, Microsoft
